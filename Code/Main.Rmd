---
title: "Predicting Transcription Factor Binding using ChIP-seq Data"
author: "Hamish Patten"
date: "`r Sys.Date()`"
output: 
  pdf_document
---

## Introduction

Fold enrichment - this is a normalisation method of the ChIP-seq signals per slice, which normalises the signal to a given noise level of the experiment. This is also referred to as the 'signal-to-noise' method. Note that the noise level can be produced from a control experiment where no antibody is present and thus no protein in particular is targeted to be analysed.

## Data Wrangling
 Let us read in the peak data first. Note that we remove random and chrUn sequences from our dataset, which constitutes less than 0.1% of the database.
```{r setup, include=FALSE}
dir<-"~/Documents/Coding/Other/ChIPseq"
knitr::opts_chunk$set(echo = TRUE)
# Install & Load all the necessary packages & required functions
installer<-F
source(paste0(dir,"/Code/Packages.R"))
source(paste0(dir,"/Code/LoadData.R"))
source(paste0(dir,"/Code/Functions.R"))
# Load in the ChIP-seq datasets
peaks<-LoadPeaks()
# Load also the shuffle data
shuffle<-LoadShuffle()
```

An example gene expression is 'GAGCCCCACCTGGTGTCTA...'. Let's visualise just a few entries of the rest of the variables that came with the input data:
```{r}
peaks%>%dplyr::select(-dna)%>%head()
```
The most important variables that we are interested in are the chromosomes, the start and end position (StartP and EndP, resp.), the length of the DNA sequence $|EndP - StartP|$, and the strength of the ChIP-seq signal of the gene, which I have reason to believe is normalised by the fold enrichment method. The other variables are not 100% understood, and are apparently not all that relevant.

### Exploratory Data Analysis

Let's have a look at some important plots of the peak data. Firstly, let's look at the (fold enrichment) Chip-seq signal strength, per chromosome:

```{r}
peaks%>%ggplot(aes(x=Chromosome, y=FoldEnrich))+geom_violin(aes(fill=Chromosome)) +
  ylab("Signal Strength (FE Normalised)") + 
  # theme(axis.ticks.x = element_blank(),axis.text.x = element_blank()) + 
  scale_fill_manual(breaks=c(as.character(1:22),"X"), values=rainbow(23))
```
Why are there no Y chromosomes? Does this indicate that the experiments had an entirely female-demography? This could be an example of demographic bias. Let's check the numbers per chromosome:
```{r}
peaks%>%group_by(Chromosome)%>%summarise(Counts=length(Chromosome))%>%knitr::kable()
```

We should be careful that the modelling later on is not heavily influence by the different count sizes. For example, chr1 is overrepresented and chr21 underrepresented. Let us first group the shuffle and peaks data together.

```{r,include=F}
tmp<-shuffle; tmp$Chromosome<-NA; tmp$FoldEnrich<-0; tmp$Namer<-NA; tmp$pScore<-0; tmp$Bound<-F
peaks$Bound<-T
ALL<-rbind(peaks,tmp); rm(tmp)
```
Now let's use Factor Analysis of Mixed Data (FAMD) to try to get some insight into which variables distinguish the genes from one another, forgetting the binding strength and p-score signal-to-control values for the time being.

```{r}
fammyD_all<-ALL%>%dplyr::select(Chromosome,StartP,EndP,lengthDNA,Bound)%>%
  FAMD(ncp = 2,sup.var = 5)
```
The conclusion of the FAMD is that the chromosome looks like a particularly crucial feature to include when explaining the differences between the different genes. The start and end positions of the gene also seem to contribute significantly to the first-dimension of the FAMD - the most important one, indicating that this is a strong feature that acts to separate the different genes from one another. What happens if we normalise the start and end position *per chromosome*? Let's see if that is more predictive of whether a gene will bind or not to the TF.

```{r}
ALL%<>%group_by(Chromosome)%>%mutate(modStart=StartP/min(StartP),modEnd=EndP/min(EndP))%>%ungroup()
fammyD_posA<-ALL%>%dplyr::select(Chromosome,modStart,modEnd,lengthDNA,Bound)%>%FAMD(ncp = 2,sup.var = 5)
```
This plot indicates that this FAMD has created a division between the 1000-peak-genes and the control genes whereby this difference is *orthogonal to the chromosome embedding*. This means that we can now setup our model with numeric data only, at least for the first step, which greatly facilitates pre-processing. Let's use this for the first phase of model development.

## Statistical Modelling

For this work, we will compare two different models. The first, which took me around 15 minutes to implement, is the Support Vector Machine, which is applied to the dataset without the DNA sequence involved at all. The second step is to train a Convolutional Neural Network (CNN) on the DNA sequence data. In the final model, I combine both the DNA sequence data and the length of the DNA variable into one single model. A summary of the models studied is as follows:
1. Support Vector Machine
    + with linear kernel (varying cost)
    + with radial kernel (varying sigma and cost)
    + with polynomial kernel (varying degree, scale and cost)
2. Convolutional Neural Network
    + Varying the one-hot permutations of A,C,G,T
    + Choice of optimiser: Stochastic Gradient Descent, ADAM and Ada-Delta
    + Varying hyperparameter choice of the CNN
    + Applying different layers to the CNN model
    
### Support Vector Machine

For the SVM analysis, we do not include the DNA sequence data, only the gene-specific covariates that also came in the file. We train two models on only three variables. In both models, we use the length of the DNA sequence as an input. In the first model, we also use the start and end position of the gene, not relativised to the chromosome that it was detected to be attached to. The second model uses the relativised start and end positions of the gene, relative to the chromosome. Note that the 'unbound' gene sequences (provided from the shuffle file) do not have an associated chromosome, and so are normalised amongst themselves, which may not be appropriate. 

As shown in the numbered list in the previous section, we apply linear, radial and polygon kernels in the SVM models. Stratified, repeated (10 times) 5-fold Cross-Validation is used to illustrate model performance. The metric used is the AUC (Area Under the Receiver Operating Characteristic - ROC - Curve). The results of the SVM models are as follows:

```{r,include=F}
svmDNA<-readRDS(paste0(dir,"/Results/SVM.RData"))
svmDNA$data%<>%factor()%>%as.numeric()
svmDNA$data<-!as.logical(svmDNA$data-1)
svmDNA %>% group_by(model,data)%>%summarise(AUC=mean(ROC),.groups="drop")%>%
  knitr::kable(col.names = c("Model","Chromosome-Relative","AUC"))
```
### Convolutional Neural Network

This CNN model consists of building layers of the neural network, some are 2D convolutional, some are dense layers. The setup is varied throughout the work. The principle setup is shown in the code below:
```{r}
cnn_model <- keras_model_sequential() %>%
  # Convolutional layer, including ReLu Activation Function
  layer_conv_2d(filters = 30, kernel_size = c(4,24),
                activation = 'relu', input_shape = c(4,174,1)) %>%
  # Max pooling
  layer_max_pooling_2d(pool_size = c(1, 2)) %>%
  # Prevent overfitting with a dropout layer
  layer_dropout(rate = 0.2) %>%
  # Normalisation to ensure no information is wasted
  layer_batch_normalization() %>%
  # We finish the convolutional work and move to 1D
  layer_flatten() %>%
  # Prepare for the densely-connected network, including ReLu Activation Function
  layer_dense(units = 30, activation = 'relu') %>%
  # Add another dropout layer
  layer_dropout(rate = 0.5) %>%
  # Softmax Activation Function to create probabilities which can build the AUC
  layer_dense(units = 2, activation = 'softmax') 
```

When we run our model, we use stratified, 10-times repeated 5-fold cross-validation. The performance metrics that are used are the AUC, the precision and the recall.

    
Firstly, we need to make one-hot arrays for both the peaks and the shuffle data, shown in the figure below. Before we do, let's also minimise the computation by choosing a minimum base length as the maximum sequence length out of both the shuffle and peak datasets. Although the minimum base length should be between 200-300 (the limit of the ChIP-seq experimental technology), we take the max length instead to save computation. The length is
```{r, include=F}
maxL<-max(max(str_length(peaks$dna)),max(str_length(shuffle$dna))); print(maxL)
OneHpeaks<-ConvOneHot(peaks$dna,maxL)
```
Let's have a quick preview of what the one-hot array looks like (trimmmed to the first 15 rows)
```{r}
OneHpeaks[1,,1:10]
```


```{r}
perf<-readRDS(paste0(dir,"/Results/Hyperparameter_Play.RData"))
knitr::kable(perf)
```
We see that using a larger number of CNN filters improves the prediction. Making the CNN filter row size cover across all four gene bases significantly improves prediction. Using a CNN filter column dimension of 30, and not smaller or larger, is shown to increase the predictive performance. For the pool size of the max pooling layer, the optimal value is 2, and not 1 and 4. Finally, the number of dense layers in the fully connected dense layer should be more than 10, and is comparable between using 30 and 50 layers. Across all of these hyperparameter variations, modifying the dimensionality of the CNN filter dimensions had the largest influence on the predictive performance.

